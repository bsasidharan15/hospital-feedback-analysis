# ğŸ¥ Hospital Feedback(Voice) Analysis System ğŸ’¬

An AI-powered system for analyzing customer feedback sentiments using ğŸ¤– Azure Speech-to-Text and OpenAI GPT-3.5 Turbo.

## ğŸŒŸ Features

- ğŸ™ï¸ **Batch audio transcription** (Tamil language support)
- ğŸ¤– **AI-powered sentiment analysis**
- ğŸ“¦ **JSON input/output format**
- ğŸŒ **RESTful API endpoints**
- ğŸš€ **Memory-efficient batch processing**
- ğŸ“Š **Sentiment visualization and insights**
- ğŸ”„ **Automatic conversion between audio and text**

## ğŸ“¥ Installation

```bash
# ğŸ”½ Clone the repository
git clone https://github.com/yourusername/HospitalFeedbackAnalysis.git

# ğŸ“‚ Navigate to the project directory
cd HospitalFeedbackAnalysis

# ğŸ“¦ Install required dependencies
pip install -r requirements.txt
```

## ğŸ› ï¸ Dependencies

- ğŸ **Python 3.7+**
- ğŸ—ï¸ **Flask**
- ğŸ¤ **Azure Cognitive Services Speech SDK**
- ğŸ§  **OpenAI API**
- ğŸ”‘ **python-dotenv**
- ğŸŒ **requests**

## ğŸš€ Usage

### â–¶ï¸ Basic Usage

1. Start the Flask server:
   ```bash
   python app.py
   ```

2. Send a POST request to the API endpoint:
   ```bash
   curl -X POST http://localhost:5000/api/analyze \
     -H "Content-Type: application/json" \
     -d '{"audio_url": "https://example.com/feedback.wav"}'
   ```

### ğŸ“© Example Response

```json
{
  "transcription": "à®‰à®™à¯à®•à®³à¯ à®šà¯‡à®µà¯ˆ à®®à®¿à®•à®µà¯à®®à¯ à®¨à®©à¯à®±à®¾à®• à®‡à®°à¯à®¨à¯à®¤à®¤à¯.",
  "sentiment_analysis": {
    "sentiment": "positive",
    "issues": []
  }
}
```

## ğŸ“Œ API Reference

### ğŸ”¹ POST `/api/analyze`

Analyzes customer feedback from an audio file.

#### ğŸ“¤ Request Body
```json
{
  "audio_url": "string (URL to the audio file)"
}
```

#### ğŸ“¥ Response
```json
{
  "transcription": "string (Transcribed text)",
  "sentiment_analysis": {
    "sentiment": "string (positive|neutral|negative)",
    "issues": ["list", "of", "key", "issues"]
  }
}
```

## ğŸ“ Examples

### ğŸ§ Analyzing Feedback

```python
import requests

url = "http://localhost:5000/api/analyze"
payload = {
    "audio_url": "https://example.com/feedback.wav"
}

response = requests.post(url, json=payload)
print(response.json())
```

### ğŸ”„ Batch Processing

For batch processing, you can loop through multiple audio URLs and send requests to the API.

```python
audio_urls = [
    "https://example.com/feedback1.wav",
    "https://example.com/feedback2.wav",
    "https://example.com/feedback3.wav"
]

for url in audio_urls:
    response = requests.post("http://localhost:5000/api/analyze", json={"audio_url": url})
    print(response.json())
```

## âš™ï¸ Configuration

1. Create a `.env` file in the root directory:
   ```bash
   cp config/.env.example .env
   ```

2. Add your **Azure** and **OpenAI** credentials:
   ```
   AZURE_SPEECH_KEY=your_azure_speech_key
   AZURE_SPEECH_REGION=your_azure_region
   AZURE_OPENAI_KEY=your_openai_key
   AZURE_OPENAI_ENDPOINT=your_openai_endpoint
   AZURE_OPENAI_DEPLOYMENT_NAME=your_deployment_name
   ```

## ğŸ¤ Contributing

1. ğŸ´ Fork the repository
2. ğŸŒ± Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. ğŸ“ Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. ğŸ“¤ Push to the branch (`git push origin feature/AmazingFeature`)
5. ğŸ”„ Open a Pull Request

## ğŸ“œ License

This project is licensed under the **Apache 2.0 License** - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¨â€ğŸ’» Author

**Sasidharan B**

## ğŸ™Œ Acknowledgments

- ğŸ¤ Thanks to **Azure Cognitive Services** for Speech-to-Text capabilities
- ğŸ¤– Thanks to **OpenAI** for GPT-3.5 Turbo sentiment analysis
- ğŸ—ï¸ Built with **Flask** and **Python**
